package demo

import com.voxai.domain.model.*
import com.voxai.util.audio.*
import kotlinx.coroutines.runBlocking

/**
 * VoxAI é«˜çº§å£°éŸ³å…‹éš†åŠŸèƒ½æ¼”ç¤º
 * å±•ç¤ºå¦‚ä½•ä½¿ç”¨å„ç§å£°éŸ³å…‹éš†æŠ€æœ¯å’Œè‡ªå®šä¹‰æ¨¡å‹
 */
object VoiceCloningDemo {

    @JvmStatic
    fun main(args: Array<String>) = runBlocking {
        println("ğŸ™ï¸ VoxAI é«˜çº§å£°éŸ³å…‹éš†åŠŸèƒ½æ¼”ç¤º")
        println("=" * 50)

        // 1. åŸºç¡€éŸ³æ•ˆæ¼”ç¤º
        demonstrateBasicEffects()
        
        // 2. é«˜çº§å£°éŸ³å…‹éš†æ¼”ç¤º
        demonstrateAdvancedVoiceCloning()
        
        // 3. è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒæ¼”ç¤º
        demonstrateCustomModelTraining()
        
        // 4. å£°éŸ³ç‰¹å¾è½¬æ¢æ¼”ç¤º
        demonstrateVoiceFeatureConversion()
        
        // 5. è´¨é‡ä¼˜åŒ–æ¼”ç¤º
        demonstrateQualityOptimization()
        
        println("\nâœ¨ æ¼”ç¤ºå®Œæˆï¼VoxAI è®©å£°éŸ³æ›´æœ‰åˆ›æ„ï¼")
    }

    private suspend fun demonstrateBasicEffects() {
        println("\nğŸ¯ 1. åŸºç¡€éŸ³æ•ˆæ¼”ç¤º")
        println("-" * 30)
        
        val processor = VoiceEffectProcessor()
        val testAudio = createTestAudio("Hello, this is a test audio.")
        
        // æµ‹è¯•å„ç§åŸºç¡€éŸ³æ•ˆ
        val basicEffects = listOf(
            VoiceEffect.NONE,
            VoiceEffect.MALE,
            VoiceEffect.FEMALE,
            VoiceEffect.CHILD,
            VoiceEffect.ROBOT,
            VoiceEffect.MONSTER
        )
        
        basicEffects.forEach { effect ->
            val processedAudio = processor.applyEffect(testAudio, effect)
            println("âœ“ ${effect.displayName} æ•ˆæœåº”ç”¨æˆåŠŸ")
        }
    }

    private suspend fun demonstrateAdvancedVoiceCloning() {
        println("\nğŸŒŸ 2. é«˜çº§å£°éŸ³å…‹éš†æ¼”ç¤º")
        println("-" * 30)
        
        val processor = AdvancedVoiceCloningProcessor()
        val testAudio = createTestAudio("Welcome to the future of voice technology!")
        
        // æ¼”ç¤ºé¢„è®¾è§’è‰²å£°éŸ³
        val clonedEffects = listOf(
            VoiceEffect.LAZY_CAT to "æ‡’æ´‹æ´‹",
            VoiceEffect.SPONGEBOB to "æµ·ç»µå®å®",
            VoiceEffect.ELSA to "è‰¾èå…¬ä¸»",
            VoiceEffect.OPTIMUS_PRIME to "æ“å¤©æŸ±",
            VoiceEffect.MINION to "å°é»„äºº",
            VoiceEffect.PORKY_PIG to "çŒªçŒªä¾ "
        )
        
        clonedEffects.forEach { (effect, name) ->
            val processedAudio = processor.applyAdvancedEffect(testAudio, effect)
            println("âœ“ $name å£°éŸ³å…‹éš†æˆåŠŸ")
            
            // æ˜¾ç¤ºå£°éŸ³ç‰¹å¾
            effect.voiceCharacteristics?.let { characteristics ->
                println("   - æƒ…æ„Ÿ: ${characteristics.emotion}")
                println("   - æ€§åˆ«: ${characteristics.gender}")
                println("   - å¹´é¾„: ${characteristics.age}")
            }
        }
    }

    private suspend fun demonstrateCustomModelTraining() {
        println("\nğŸ“ 3. è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒæ¼”ç¤º")
        println("-" * 30)
        
        val processor = AdvancedVoiceCloningProcessor()
        
        // åˆ›å»ºè®­ç»ƒæ ·æœ¬
        val trainingSamples = listOf(
            createTestAudio("è¿™æ˜¯ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·æœ¬"),
            createTestAudio("è¿™æ˜¯ç¬¬äºŒä¸ªè®­ç»ƒæ ·æœ¬"),
            createTestAudio("è¿™æ˜¯ç¬¬ä¸‰ä¸ªè®­ç»ƒæ ·æœ¬"),
            createTestAudio("è¿™æ˜¯ç¬¬å››ä¸ªè®­ç»ƒæ ·æœ¬"),
            createTestAudio("è¿™æ˜¯ç¬¬äº”ä¸ªè®­ç»ƒæ ·æœ¬")
        )
        
        // å®šä¹‰ç›®æ ‡å£°éŸ³ç‰¹å¾
        val targetCharacteristics = VoiceCharacteristics(
            emotion = Emotion.CHEERFUL,
            gender = Gender.FEMALE,
            age = Age.YOUNG_ADULT,
            formantShift = 1.2f
        )
        
        // è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹
        println("ğŸ”„ å¼€å§‹è®­ç»ƒè‡ªå®šä¹‰å£°éŸ³æ¨¡å‹...")
        val customModel = processor.trainCustomVoiceModel(
            name = "æ¬¢å¿«å¥³å£°æ¨¡å‹",
            trainingSamples = trainingSamples,
            voiceCharacteristics = targetCharacteristics
        )
        
        println("âœ“ è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒæˆåŠŸ!")
        println("   - æ¨¡å‹ID: ${customModel.id}")
        println("   - è®­ç»ƒæ ·æœ¬æ•°: ${customModel.trainingSamples}")
        println("   - ç›®æ ‡æƒ…æ„Ÿ: ${targetCharacteristics.emotion}")
        
        // ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
        val testAudio = createTestAudio("ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹æµ‹è¯•å£°éŸ³è½¬æ¢æ•ˆæœ")
        val processedAudio = processor.applyAdvancedEffect(
            testAudio, 
            VoiceEffect.CUSTOM, 
            customModel
        )
        
        println("âœ“ è‡ªå®šä¹‰æ¨¡å‹åº”ç”¨æˆåŠŸ!")
    }

    private suspend fun demonstrateVoiceFeatureConversion() {
        println("\nğŸ”§ 4. å£°éŸ³ç‰¹å¾è½¬æ¢æ¼”ç¤º")
        println("-" * 30)
        
        val converter = RealTimeVoiceConverter()
        val extractor = VoiceFeatureExtractor()
        
        // æå–åŸå§‹å£°éŸ³ç‰¹å¾
        val originalAudio = createTestAudio("åŸå§‹å£°éŸ³æ ·æœ¬")
        val originalFeatures = extractor.extractFeatures(originalAudio)
        
        println("ğŸ“Š åŸå§‹å£°éŸ³ç‰¹å¾:")
        println("   - åŸºé¢‘: ${originalFeatures.pitch} Hz")
        println("   - èƒ½é‡: ${originalFeatures.energy}")
        println("   - è¯­é€Ÿ: ${originalFeatures.speakingRate}")
        
        // è½¬æ¢ä¸ºä¸åŒç‰¹å¾
        val conversions = listOf(
            VoiceCharacteristics(Emotion.HAPPY, Gender.FEMALE, Age.YOUNG_ADULT) to "å¿«ä¹å¥³æ€§é’å¹´",
            VoiceCharacteristics(Emotion.AUTHORITATIVE, Gender.MALE, Age.ADULT) to "æƒå¨ç”·æ€§æˆå¹´",
            VoiceCharacteristics(Emotion.PLAYFUL, Gender.NEUTRAL, Age.CHILD) to "è°ƒçš®ä¸­æ€§å„¿ç«¥"
        )
        
        conversions.forEach { (characteristics, description) ->
            val convertedFeatures = converter.convertVoice(
                sourceFeatures = originalFeatures,
                targetCharacteristics = characteristics,
                pitchShift = 1.0f,
                speedMultiplier = 1.0f
            )
            
            println("âœ“ è½¬æ¢ä¸º $description:")
            println("   - åŸºé¢‘å˜åŒ–: ${originalFeatures.pitch} â†’ ${convertedFeatures.pitch} Hz")
            println("   - èƒ½é‡å˜åŒ–: ${originalFeatures.energy} â†’ ${convertedFeatures.energy}")
            println("   - è¯­é€Ÿå˜åŒ–: ${originalFeatures.speakingRate} â†’ ${convertedFeatures.speakingRate}")
        }
    }

    private suspend fun demonstrateQualityOptimization() {
        println("\nâš¡ 5. è´¨é‡ä¼˜åŒ–æ¼”ç¤º")
        println("-" * 30)
        
        val processor = AdvancedVoiceCloningProcessor()
        val testAudio = createTestAudio("è´¨é‡ä¼˜åŒ–æµ‹è¯•éŸ³é¢‘")
        
        // ä¸åŒè´¨é‡è®¾ç½®çš„å¤„ç†
        val qualitySettings = listOf(
            VoiceQualitySettings(16000, 64) to "åŸºç¡€è´¨é‡",
            VoiceQualitySettings(22050, 128) to "æ ‡å‡†è´¨é‡",
            VoiceQualitySettings(44100, 256) to "é«˜è´¨é‡",
            VoiceQualitySettings(48000, 320) to "æé«˜è´¨é‡"
        )
        
        qualitySettings.forEach { (settings, description) ->
            println("ğŸµ $description å¤„ç†:")
            println("   - é‡‡æ ·ç‡: ${settings.sampleRate} Hz")
            println("   - æ¯”ç‰¹ç‡: ${settings.bitrate} kbps")
            
            // æ¨¡æ‹Ÿè´¨é‡ä¼˜åŒ–å¤„ç†
            val processedAudio = processor.applyAdvancedEffect(testAudio, VoiceEffect.ELSA)
            println("   âœ“ å¤„ç†å®Œæˆï¼ŒéŸ³é¢‘å¤§å°: ${processedAudio.size} bytes")
        }
        
        // é«˜çº§è®¾ç½®ä¼˜åŒ–
        val advancedSettings = AdvancedVoiceSettings(
            enableRealTimeProcessing = true,
            enableNoiseSuppression = true,
            preserveEmotion = true,
            voiceQuality = 0.95f
        )
        
        println("\nğŸ”¬ é«˜çº§è®¾ç½®ä¼˜åŒ–:")
        println("   - å®æ—¶å¤„ç†: ${advancedSettings.enableRealTimeProcessing}")
        println("   - å™ªéŸ³æŠ‘åˆ¶: ${advancedSettings.enableNoiseSuppression}")
        println("   - æƒ…æ„Ÿä¿æŒ: ${advancedSettings.preserveEmotion}")
        println("   - éŸ³è´¨: ${(advancedSettings.voiceQuality * 100).toInt()}%")
    }

    private fun createTestAudio(text: String): ByteArray {
        // åˆ›å»ºæ¨¡æ‹ŸéŸ³é¢‘æ•°æ®
        val duration = text.length * 100 // æ¯ä¸ªå­—ç¬¦100ms
        val sampleRate = 44100
        val samples = (duration * sampleRate / 1000)
        val audioData = ByteArray(samples * 2)
        
        // ç”ŸæˆåŸºäºæ–‡æœ¬å†…å®¹çš„éŸ³é¢‘æ³¢å½¢
        for (i in 0 until samples) {
            val time = i.toFloat() / sampleRate
            val frequency = 200f + (text.hashCode() % 200) // åŸºäºæ–‡æœ¬ç”Ÿæˆä¸åŒé¢‘ç‡
            val amplitude = Math.sin(2 * Math.PI * frequency * time).toFloat()
            val sample = (amplitude * Short.MAX_VALUE * 0.3).toInt()
            
            audioData[i * 2] = (sample and 0xFF).toByte()
            audioData[i * 2 + 1] = ((sample shr 8) and 0xFF).toByte()
        }
        
        return audioData
    }
}

/**
 * å£°éŸ³è´¨é‡è®¾ç½®æ•°æ®ç±»
 */
data class VoiceQualitySettings(
    val sampleRate: Int,
    val bitrate: Int
)

/**
 * é«˜çº§å£°éŸ³è®¾ç½®æ•°æ®ç±»
 */
data class AdvancedVoiceSettings(
    val enableRealTimeProcessing: Boolean,
    val enableNoiseSuppression: Boolean,
    val preserveEmotion: Boolean,
    val voiceQuality: Float
)